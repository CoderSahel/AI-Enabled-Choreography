{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(\"data\\mariel_beyond.npy\")\n",
    "motion_data=np.array(res)\n",
    "# Scale the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(motion_data.reshape(-1, 3)).reshape(motion_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 6803, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data=scaled_data.transpose(1, 0, 2).reshape(6803, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6803, 165)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 125\n",
    "num_features = scaled_data.shape[1]\n",
    "\n",
    "# Reshape data into smaller sequences\n",
    "num_sequences = scaled_data.shape[0] // time_steps\n",
    "scaled_data = scaled_data[:num_sequences*time_steps]  # truncate data to a size divisible by time_steps\n",
    "data = scaled_data.reshape((num_sequences, time_steps, num_features))\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 125, 165)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninth_seq_data=data[11]\n",
    "ninth_seq=ninth_seq_data.reshape(125, 55, 3).transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 125, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninth_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ninth\", ninth_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMVAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size):\n",
    "        super(LSTMVAE, self).__init__()\n",
    "        self.encoder_lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.encoder_mean = nn.Linear(hidden_size, latent_size)\n",
    "        self.encoder_logvar = nn.Linear(hidden_size, latent_size)\n",
    "        self.decoder_lstm = nn.LSTM(latent_size, hidden_size, batch_first=True)\n",
    "        self.decoder_output = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        _, (h_n, _) = self.encoder_lstm(x)\n",
    "        mean = self.encoder_mean(h_n.squeeze(0))\n",
    "        logvar = self.encoder_logvar(h_n.squeeze(0))\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        _, (h_n, _) = self.decoder_lstm(z.unsqueeze(1))\n",
    "        output = self.decoder_output(h_n.squeeze(0))\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        reconstructed = self.decode(z)\n",
    "        return reconstructed, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # Calculate the mean squared error loss only for non-padded elements\n",
    "    mask = (x != 0).float()  # Assuming 0 is used for padding\n",
    "    recon_x_trimmed = recon_x[:, :x.size(1), :]  # Trim recon_x to match the length of x\n",
    "    recon_loss = nn.functional.mse_loss(recon_x_trimmed, x, reduction='none')  # Calculate loss element-wise\n",
    "    recon_loss = torch.sum(recon_loss * mask) / torch.sum(mask)  # Take the average over non-padded elements\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_seq = batch[0].float()\n",
    "            recon_batch, mu, logvar = model(input_seq)\n",
    "            loss = criterion(recon_batch, input_seq, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     10\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m input_seq \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      8\u001b[0m recon_batch, mu, logvar \u001b[38;5;241m=\u001b[39m model(input_seq)\n\u001b[1;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m, in \u001b[0;36mloss_function\u001b[1;34m(recon_x, x, mu, logvar)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(recon_x, x, mu, logvar):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Calculate the mean squared error loss only for non-padded elements\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Assuming 0 is used for padding\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     recon_x_trimmed \u001b[38;5;241m=\u001b[39m \u001b[43mrecon_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Trim recon_x to match the length of x\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     recon_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(recon_x_trimmed, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Calculate loss element-wise\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     recon_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(recon_loss \u001b[38;5;241m*\u001b[39m mask) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(mask)  \u001b[38;5;66;03m# Take the average over non-padded elements\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_loader = DataLoader(TensorDataset(torch.tensor(train_data).float()), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, optimizer, and train\n",
    "input_size = train_data.shape[-1]\n",
    "hidden_size = 64\n",
    "latent_size = 16\n",
    "model = LSTMVAE(input_size, hidden_size, latent_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "train(model, train_loader, loss_function, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(TensorDataset(torch.tensor(test_data).float()), batch_size=1, shuffle=False)\n",
    "def generate_new_data(model, test_loader):\n",
    "    model.eval()\n",
    "    generated_data = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_seq = batch.float()\n",
    "            recon_batch, _, _ = model(input_seq)\n",
    "            generated_data.append(recon_batch.squeeze().numpy())\n",
    "    return np.array(generated_data)\n",
    "\n",
    "generated_data = generate_new_data(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SIH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
